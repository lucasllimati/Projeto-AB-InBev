# üéØ Objetivo

Consumir dados de uma API, transformos dados e utilizando o data lake com a [arquitetura medallion](https://learn.microsoft.com/pt-br/azure/databricks/lakehouse/medallion).

---

## üìã Instru√ß√µes do Desafio

- **API:** Use a Open Brewery DB API para buscar os dados de cervejarias.  
  üëâ [https://www.openbrewerydb.org/](https://www.openbrewerydb.org/)

- **Orquestra√ß√£o:** Utilize uma ferramenta de orquestra√ß√£o de sua prefer√™ncia (Airflow, Luigi, Mage etc.) para construir o pipeline de dados, incluindo agendamento, tentativas e tratamento de erros.

- **Linguagem:** Use a linguagem de sua escolha para consumir e transformar os dados. Inclua testes no seu c√≥digo.  
  *Python e PySpark s√£o preferidas.*

- **Containeriza√ß√£o:** O uso de Docker ou Kubernetes conta pontos extras.

- **Arquitetura do Data Lake (Medallion):**
  - **Camada Bronze:** Armazene os dados brutos da API no formato nativo (JSON, CSV, etc.)
  - **Camada Prata:** Transforme os dados para um formato colunar (parquet ou delta) e particione por localiza√ß√£o da cervejaria.
  - **Camada Ouro:** Crie uma vis√£o agregada com a quantidade de cervejarias por tipo e localiza√ß√£o.

- **Monitoramento e Alertas:** Descreva como voc√™ implementaria o monitoramento e alertas (falhas no pipeline, problemas de qualidade de dados etc.)

- **Reposit√≥rio:** Crie um reposit√≥rio p√∫blico no GitHub com sua solu√ß√£o, explicando decis√µes de projeto e instru√ß√µes para execu√ß√£o.

- **Servi√ßos de Nuvem:** Caso utilize servi√ßos em nuvem, forne√ßa instru√ß√µes de configura√ß√£o separadamente (n√£o poste no reposit√≥rio p√∫blico).

---

## üìä Tabela Explicativa por T√≥pico

| T√≥pico                    | Descri√ß√£o                                                                 |
|--------------------------|--------------------------------------------------------------------------|
| **API**                  | Open Brewery DB - fornece informa√ß√µes sobre cervejarias nos EUA.         |
| **Orquestra√ß√£o**         | Airflow, Luigi, Mage, etc. (mostrar agendamento, tentativas e erros)     |
| **Linguagem**            | Qualquer linguagem (prefer√™ncia: Python + PySpark) com testes inclu√≠dos  |
| **Containeriza√ß√£o**      | Uso de Docker ou Kubernetes √© opcional, mas agrega pontos                |
| **Bronze Layer**         | Dados crus da API, sem transforma√ß√£o (JSON, CSV, etc.)                   |
| **Silver Layer**         | Dados transformados em parquet/delta, particionados por localiza√ß√£o      |
| **Gold Layer**           | Dados agregados: n√∫mero de cervejarias por tipo e localiza√ß√£o            |
| **Monitoramento/Alertas**| Estrat√©gia para capturar falhas e problemas de qualidade no pipeline     |
| **Reposit√≥rio GitHub**   | C√≥digo + documenta√ß√£o clara e instru√ß√µes para executar                   |
| **Servi√ßos em Nuvem**    | Instru√ß√µes de configura√ß√£o separadas (caso usados)                       |

---

## Como executar a aplica√ß√£o

### Software necess√°rios

Para executar a apli√ß√£o voc√™ ir√° precisar do [Docker Desktop](https://www.docker.com/), caso n√£o tenha, favor instalar (Vers√£o utilizada: 4.41.2).

Tamb√©m √© necess√°rio uma IDE, no caso, sugiro o [VS Code](https://code.visualstudio.com/), que foi testado nesse desenvolvimento, mas as demais IDEs tamb√©m devem funcionar, caso n√£o tenha, favor instalar.

### Baixar reposit√≥rio Git

Para baixar tamb√©m √© necess√°rio ter o [Git](https://git-scm.com/downloads) instalado para conseguir baixar diretamente.

1. Abra o terminal CMD/Git
    - Tamb√©m √© possivel baixar diretamente no diret√≥rio, clique no bot√£o "<> Code", depois Download ZIP. Extraia o arquivo para a pasta desejada e depois continue a partir do t√≥pico 5.
  
2. Selecione o repositorio desejado.

    ```bash
    cd ~/Documentos
    ```

3. Clone o reposit√≥rioo com o comando:

    ```bash
    git clone https://github.com/lucasllimati/Projeto-AB-InBev.git
    ```

4. Entre na pasta

    ```bash
    cd Projeto-AB-InBev
    ```

5. Abra o VS Code como comando. Ou mesmo, abra o VS Code manualmente, v√° em arquivo, abrir pasta e selecione a pasta onde baixou o arquivo.

    ```bash
      code .
    ```

6. Abra o terminal e execute o c√≥digo (cria√ß√£o do container)

    ```bash
      docker-compose up -d
    ```

7. Quando terminar de instalar, abra o navegado e acesse o link [http://localhost:8080/](http://localhost:8080/)
    User: airflow
    Password: airflow

8. Quando abrir o Airflow, procure a DAG *brewery_pipeline* e do lado esquerdo, abaixo de actions clique em play.

9. Para acompanhar a execu√ß√£o, clice na *brewery_pipeline* edepois em Graph.

10. Quando todas as caixinhas ficarem verde escuro o processo foi executado com sucesso.

11. Para verificar os arquivos, abra a pasta data_lake e l√° estar√° os arquivos atualizados do processo de extra√ß√£o da Open Brewery DB API.

12. Para finalizar, para a execu√ß√£o do container com o c√≥digo abaixo

    ```bash
      docker-compose down
    ```

## L√≥gica do desenvolvimento

Abaixo esta mais detalhes de como foi desenvolvido esse processo.

### Main.py

Extra√ß√£o: Realiza a extra√ß√£o dos dados da API Open Brewery DB, coletando a lista completa de cervejarias de forma paginada. Os dados s√£o armazenados em formato JSON na camada bronze. Tamb√©m h√° uma etapa adicional que converte esse JSON para CSV, facilitando a visualiza√ß√£o e explora√ß√£o.

Transforma√ß√£o (Limpeza): Remove espa√ßos em branco das colunas, elimina registros inv√°lidos (como linhas sem brewery_type e IDs duplicados), preenche valores nulos na coluna website_url com "N/A", normaliza os textos (sem acentos, tudo em min√∫sculas e sem espa√ßos extras) e valida as coordenadas geogr√°ficas (removendo valores fora dos limites esperados). Ap√≥s os tratamentos, os dados s√£o particionados por estado e salvos em formato .parquet na camada silver.

Agrega√ß√£o: Consolida os dados transformados, agrupando por tipo de cervejaria e estado, e salva o resultado final na camada gold, tamb√©m em formato .parquet.

Obs: A etapa de testes foi desenvolvida de forma simples, utilizando o Try Catch para exibir os erros e jogando no log.

Resumo:
O pipeline segue estas etapas:
Extra√ß√£o: Coleta todos os dados da API paginadamente.
Convers√£o: Transforma JSON ‚Üí CSV.
Transforma√ß√£o: Aplica tratamentos robustos (limpeza, padroniza√ß√£o, filtro e particionamento).
Agrega√ß√£o: Agrupa dados por tipo de cervejaria e estado.

### Brewery_dag.py

Faz as configura√ß√µes com as informa√ß√µes b√°sicas, execu√ß√£o as fun√ß√µes e tamb√©m o agendamento recorrente para a aplica√ß√£o executar.

### docker-compose.yaml

Foi utilizado como refencia o modelo que esta no pr√≥prio site do airflow [link](www.teste.com).

Esse arquivo √© um docker-compose.yaml que configura um ambiente de Apache Airflow, com todas as configura√ß√µes necess√°rias da aplica√ß√£o que esta no docker para a integra√ß√£o com o orquestrador Apache Web.

### Dockerfile

Esse Dockerfile √© uma configura√ß√£o de um cont√™iner para rodar um projeto baseado em Apache Airflow com Python, onde as depend√™ncias e arquivos necess√°rios s√£o instalados e copiados para dentro do cont√™iner, junto com as bibliotecas e depend√™ncias.

### Airflow

Interface gr√°fica para executar, monitor os processos (DAGs) que est√£o sendo executadas. Durante a execu√ß√£o ele vai criando logs extras de toda a execu√ß√£o, melhorando a visibilidade e entendimento em caso de problemas.
![Airflow - Graph - Fluxo de dados](image-2.png)
![Airflow - Gantt](image-1.png)

#### Logs

O processo gera logs do pr√≥prio fluxo do Airflow e tamb√©m de etapas que foram criadas durante o desenvolvimento do main.py.
![Exemplo do Log - Transformar Dados](image.png)

## ‚úÖ Checklist do Projeto

- Simplificar a configura√ß√£o do docker-compose.yaml e Dockerfil. Esta com a imagem um pouco pesada e como √© um processo simples, por√©m como tive v√°rios problemas de compatibilidade, acabei deixndo dessa forma.
- Melhoria dos Logs (Foram desenvolvidos no Main.py), por√©m quando passei para o Airflow ele acaba ficando um pouco fora do padr√£o e seria interessante simplificar e padronizar os logs.
- Envio de e-mail em caso de sucesso ou falha.
- Cria√ß√£o de cen√°rios de testes.
- Ap√≥s as melhorias publicar em Nuvem, facilitando a manuten√ß√£o e n√£o dependendo de uma m√°quina especifica para executar o processo.

Checklist de acompanhamento:

### üîÑ API

- [x] Conectar √† API Open Brewery DB  
- [x] Coletar e armazenar os dados brutos

### ‚öôÔ∏è Orquestra√ß√£o

- [x] Escolher ferramenta (Airflow, Luigi, Mage, etc.)  
- [x] Implementar agendamento  
- [x] Implementar tentativas e tratamento de erros

### üêç Linguagem

- [x] Escolher linguagem (prefer√™ncia: Python/PySpark)  
- [ ] Criar testes para o c√≥digo

### üê≥ Containeriza√ß√£o (opcional, mas recomendada)

- [x] Criar Dockerfile  
- [x] Executar aplica√ß√£o em container

### üèóÔ∏è Arquitetura Medallion

- [x] Bronze Layer: salvar dados brutos da API  
- [x] Silver Layer: transformar para parquet/delta  
- [x] Silver Layer: particionar por localiza√ß√£o  
- [x] Gold Layer: criar agrega√ß√£o por tipo e localiza√ß√£o

### üì° Monitoramento e Alertas

- [x] Definir abordagem para monitoramento de falhas e qualidade de dados

### üìÅ Reposit√≥rio GitHub

- [x] Subir projeto para reposit√≥rio p√∫blico  
- [x] Documentar decis√µes t√©cnicas  
- [x] Incluir instru√ß√µes de execu√ß√£o (README)

### ‚òÅÔ∏è Servi√ßos em Nuvem (se aplic√°vel)

- [ ] Incluir instru√ß√µes de configura√ß√£o fora do reposit√≥rio

### ‚è±Ô∏è Prazos

- [x] Entregar em at√© 1 semana  
- [x] Compartilhar link do reposit√≥rio GitHub com o time BEES
